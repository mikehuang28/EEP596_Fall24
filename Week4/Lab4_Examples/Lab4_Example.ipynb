{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2934e8fa",
   "metadata": {},
   "source": [
    "# <span style='color:blue'> LAB 4: </span>\n",
    "# <span style='color:blue'> CONVOLUTIONAL NEURAL NETWORKS </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835b6358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1654d355",
   "metadata": {},
   "source": [
    "# <span style='color:red'> Part 3: Training CNNs (MNIST Classification example) ------------------------------------</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8a5cf6",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc88120e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST training and testing dataset\n",
    "\n",
    "# 1000 training features/targets \n",
    "train_features = np.load('mnist_train_features.npy') \n",
    "train_targets = np.load('mnist_train_targets.npy')\n",
    "\n",
    "# 100 testing features/targets \n",
    "test_features = np.load('mnist_test_features.npy')\n",
    "test_targets = np.load('mnist_test_targets.npy')\n",
    "\n",
    "# Print the shape of training/testing features and targets\n",
    "print(train_features.shape, train_targets.shape)\n",
    "print(test_features.shape, test_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c1e6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize some training samples\n",
    "\n",
    "plt.figure(figsize = (10, 10))\n",
    "\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(train_features[0], cmap = 'Greys')\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(train_features[1], cmap = 'Greys')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(train_features[2], cmap = 'Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9be3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import StandardScaler from scikit-learn\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# First flatten each image into 784 to convert features from 3D -> 2D arrays\n",
    "train_features_flat = train_features.reshape((1000, 28 * 28))\n",
    "test_features_flat = test_features.reshape((100, 28 * 28))\n",
    "\n",
    "# Use standard scaler to scale the flattened images\n",
    "# Reshape back to 28 x 28 since CNNs accept 2D tensors as inputs\n",
    "scaler = StandardScaler()\n",
    "train_features = scaler.fit_transform(train_features_flat).reshape((1000, 28, 28))\n",
    "test_features = scaler.fit_transform(test_features_flat).reshape((100, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2025caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking the first 100 training features/targets as validation dataset\n",
    "validation_features = train_features[:100]\n",
    "validation_targets = train_targets[:100]\n",
    "\n",
    "# Taking the remaining 900 training features/targets as training dataset\n",
    "train_features = train_features[100:]\n",
    "train_targets = train_targets[100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d06c539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape train/validation/test features to according to (N, channels, height, width) where N is number of samples\n",
    "\n",
    "train_features = np.reshape(train_features, (900, 1, 28, 28))\n",
    "validation_features = np.reshape(validation_features, (100, 1, 28, 28))\n",
    "test_features = np.reshape(test_features, (100, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07aab655",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8355384",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(CNNModel, self).__init__()\n",
    "        \n",
    "        # First convolution layer (1 channel -> 16 channels, preserve original dimension by adding padding = 2)\n",
    "        self.cnn1 = torch.nn.Conv2d(in_channels=1, out_channels=16, \n",
    "                              kernel_size=5, stride=1, padding=2)\n",
    "        \n",
    "        # First max pooling layer with kernel size = 2\n",
    "        self.maxpool1 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "         \n",
    "        # Second convolution layer (16 channel -> 32 channels, preserve dimension by adding padding = 2)\n",
    "        self.cnn2 = torch.nn.Conv2d(in_channels=16, out_channels=32, \n",
    "                              kernel_size=5, stride=1, padding=2)\n",
    "        \n",
    "        # Second max pooling layer with kernel size = 2\n",
    "        self.maxpool2 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        \n",
    "        # Fully connected layer that takes the flattened output of maxpool2 (32, 7 ,7) -> (1568) and output 10 classes\n",
    "        self.fc1 = torch.nn.Linear(32 * 7 * 7, 10) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # input image -> conv1 -> relu -> maxpool1\n",
    "        conv1_out = torch.nn.functional.relu(self.cnn1(x))       \n",
    "        pool1_out = self.maxpool1(conv1_out)\n",
    "        \n",
    "        # maxpool1 output -> conv2 -> relu -> maxpool2\n",
    "        conv2_out = torch.nn.functional.relu(self.cnn2(pool1_out))    \n",
    "        pool2_out = self.maxpool2(conv2_out)\n",
    "        \n",
    "        # flatten the maxpool2 output to be used as input into FCN layer\n",
    "        fcn_input = pool2_out.view(pool2_out.size(0), -1)\n",
    "    \n",
    "        # Use the raw output of the fully connected layer as the final output\n",
    "        output = self.fc1(fcn_input)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881a9839",
   "metadata": {},
   "source": [
    "## Define Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d668a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix the random seed so that model performance is reproducible\n",
    "torch.manual_seed(55)\n",
    "\n",
    "# Define the model class\n",
    "model = CNNModel()\n",
    "\n",
    "# Define learning rate, epochs and batchsize (for mini-batch gradient)\n",
    "learning_rate = 0.003\n",
    "epochs = 15\n",
    "batchsize = 100\n",
    "\n",
    "# CrossEntropyLoss as loss function and Adam as optimizer\n",
    "# NOTE: CrossEntropyLoss automatically applies softmax to the output layer \n",
    "# so no need to apply manual softmax to the output layer in forward function\n",
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "# Print modele specific. Add .cuda() to move your model to GPU\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7357ffe",
   "metadata": {},
   "source": [
    "## Identify Tracked Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638259ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholders for training loss and validation accuracy during training\n",
    "# Using empty Python list as train_loss_list since we will be appending loss value per iteration\n",
    "# each iteration = single fwd/bwd pass of a training mini-batch  \n",
    "\n",
    "train_loss_list = []\n",
    "validation_accuracy_list = np.zeros((epochs,))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fab1a1",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a5f590",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm # Use \"for epoch in tqdm.trange(epochs):\" to see the progress bar\n",
    "\n",
    "# Convert train/validation/test sets into torch tensors\n",
    "# Features -> floating numbers, Target labels -> int64 format\n",
    "train_inputs = torch.from_numpy(train_features).float()\n",
    "train_targets = torch.from_numpy(train_targets).long()\n",
    "\n",
    "validation_inputs = torch.from_numpy(validation_features).float()\n",
    "validation_targets = torch.from_numpy(validation_targets).long()\n",
    "\n",
    "testing_inputs = torch.from_numpy(test_features).float()\n",
    "testing_targets = torch.from_numpy(test_targets).long()\n",
    "\n",
    "# Use torch.split() function to split the training inputs/targets into mini-batches\n",
    "# See documentation of torch.split() https://pytorch.org/docs/stable/generated/torch.split.html\n",
    "train_batches_features = torch.split(train_inputs, batchsize)\n",
    "train_batches_targets = torch.split(train_targets, batchsize)\n",
    "\n",
    "# length of train_batches_features = total number of mini-batches in the training set\n",
    "batch_split_num = len(train_batches_features)\n",
    "\n",
    "# Training Loop ---------------------------------------------------------------------------------------\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    # For each mini-batch number k, grab k-th training feature mini-batch and target mini-batch\n",
    "    # and perform fwd/bwd pass on the network\n",
    "    \n",
    "    for k in range(batch_split_num):\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        train_batch_outputs = model(train_batches_features[k])\n",
    "\n",
    "        loss = loss_func(train_batch_outputs, train_batches_targets[k])\n",
    "\n",
    "        train_loss_list.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    # Compute Validation Accuracy ----------------------------------------------------------------------\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        validation_outputs = model(validation_inputs)\n",
    "\n",
    "        correct = (torch.argmax(validation_outputs, dim=1) == \n",
    "                   validation_targets).type(torch.FloatTensor)\n",
    "        \n",
    "        print(\"Epoch: \"+ str(epoch), \n",
    "              \"Validation Accuracy: \" + str(np.round(correct.mean().numpy() * 100, 2)) + '%', flush=True)\n",
    "\n",
    "        validation_accuracy_list[epoch] = correct.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba1debd",
   "metadata": {},
   "source": [
    "## Visualize & Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc0863f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import seaborn for prettier plot with whitegrid style\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(style = 'whitegrid', font_scale = 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23f333c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training loss and validation accuracy throughout the training\n",
    "\n",
    "plt.figure(figsize = (15, 9))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(train_loss_list, linewidth = 3)\n",
    "plt.ylabel(\"training loss\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "sns.despine()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(validation_accuracy_list, linewidth = 3, color = 'gold')\n",
    "plt.ylabel(\"validation accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272fffea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the testing accuracy \n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    y_pred_test = model(testing_inputs)\n",
    "     \n",
    "    correct = (torch.argmax(y_pred_test, dim=1) == testing_targets).type(torch.FloatTensor)\n",
    "    \n",
    "    print(\"Testing Accuracy: \" + str(correct.mean().numpy()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
