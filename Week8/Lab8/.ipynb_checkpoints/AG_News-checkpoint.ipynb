{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7fd5c0-5ee3-4953-b605-8cbe40c72694",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import Tuple\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "from torch.utils.data import dataset\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21b6890-3642-49cf-8df9-9a68272d0c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "from torchtext.datasets import AG_NEWS\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Load dataset and initialize tokenizer\n",
    "train_iter, test_iter = AG_NEWS(root='datasets', split=('train', 'test'))\n",
    "\n",
    "label_counts = Counter()\n",
    "for label, samples in train_iter:\n",
    "    label_counts[label] += 1\n",
    "print(\"Label distribution in train_iter:\", label_counts)\n",
    "\n",
    "label_counts = Counter()\n",
    "for label, _ in test_iter:\n",
    "    label_counts[label] += 1\n",
    "print(\"Label distribution in test_iter:\", label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e78676-90c2-4f14-8d01-1980802f716b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload train_iter for use in DataLoader\n",
    "train_iter, test_iter = AG_NEWS(root='datasets', split=('train', 'test'))\n",
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "def yield_tokens(data_iter):\n",
    "    for _, text in data_iter:\n",
    "        yield tokenizer(text)\n",
    "\n",
    "# Create vocabulary with special tokens for padding and unknown words\n",
    "vocab = # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8341c3-2dd3-46fd-b130-00fd443ad785",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_pipeline(x): \n",
    "    return vocab(tokenizer(x))\n",
    "    \n",
    "# Example: Test the pipeline on a sample text\n",
    "sample_text = \"This movie was fantastic!\"\n",
    "print(text_pipeline(sample_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b1f1db-f775-4f04-aa4b-9970e92bc8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot the lenght distribution of training and testing datasets\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c576736-4c66-4395-a3a4-8bb96621d681",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# Define collate function for padding and batching\n",
    "# setting a max_seq_len helps with estimating the max gpu memory usage\n",
    "def collate_batch(batch, max_seq_len=1024):\n",
    "    labels, texts = zip(*batch)\n",
    "    # Your code here\n",
    "    return padded_texts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10bece1-f976-49af-89a5-ec8d80f0b9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class AG_NEWS_Dataset(Dataset):\n",
    "    def __init__(self, data_iter):\n",
    "        self.data_iter = list(data_iter)  # Converting the iterator to a list for easier access\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_iter)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label, text = self.data_iter[idx]\n",
    "        return label, text\n",
    "\n",
    "train_iter, test_iter = AG_NEWS(root='datasets', split=('train', 'test'))\n",
    "train_dataset = AG_NEWS_Dataset(train_iter)\n",
    "test_dataset = AG_NEWS_Dataset(test_iter)\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_batch)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dc1011-738f-4fd6-8a9b-531b754572f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, num_heads, num_encoder_layers, num_classes, dropout=0.1):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        # Your code here\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Your code here\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73167605-2bbb-478a-a6d2-b153c2ecac04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for device compatibility, prioritizing CUDA, then MPS for MacBooks with Apple Silicon, and defaulting to CPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Initialize the model, \n",
    "# Your code here\n",
    "embed_size = #\n",
    "num_heads = #\n",
    "num_encoder_layers = #\n",
    "num_classes = #\n",
    "model = TransformerModel(len(vocab), embed_size, num_heads, num_encoder_layers, num_classes)\n",
    "\n",
    "# Initialize loss function, and optimizer\n",
    "loss_fn = #\n",
    "optimizer = #\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e4490f-f735-4dca-bfc7-a6749ac7bf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, loss_fn, optimizer):\n",
    "    # Your code here\n",
    "\n",
    "\n",
    "def evaluate(model, test_loader, loss_fn):\n",
    "    # Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8272df7d-9cf9-43b1-81fb-dfcd0e2cf6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = #\n",
    "train_losses = np.zeros(num_epochs)\n",
    "train_accuracies = np.zeros(num_epochs)\n",
    "\n",
    "test_losses = np.zeros(num_epochs)\n",
    "test_accuracies = np.zeros(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d1a15f-8c50-4c7d-b487-8d132850ea02",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    # Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef204344-f2c0-45ce-8678-31e46e525ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "epochs = list(range(0, num_epochs))\n",
    "\n",
    "# Create 2x2 grid of subplots using plt.subplot\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Training Loss\n",
    "plt.subplot(2, 2, 1)  # (rows, columns, index)\n",
    "plt.plot(epochs, train_losses, color='blue', label='Train Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Testing Loss\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(epochs, test_losses, color='orange', label='Test Loss')\n",
    "plt.title('Testing Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Training Accuracy\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(epochs, train_accuracies, color='green', label='Train Accuracy')\n",
    "plt.title('Training Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Testing Accuracy\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(epochs, test_accuracies, color='red', label='Test Accuracy')\n",
    "plt.title('Testing Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Adjust layout and display\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a6ffd5-0bde-453f-9a27-2634b627af03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3eab57b-c26e-4e61-bee0-c532cb17a0a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
